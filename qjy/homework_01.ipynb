{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一次平时作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "### (a) 数据规范化\n",
    "某数据集记录了某单位成年人的身高和体重数据。身高范围为 1.4-1.9 m，体重范围为 40-90kg。请结合表1，回答下列问题： "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 表1. 体型数据表\n",
    "\n",
    "| ID | 身高 (m) | 体重 (kg) |\n",
    "|----|---------|----------|\n",
    "| 1  | 1.70    | 50       |\n",
    "| 2  | 1.60    | 50       |\n",
    "| 3  | 1.70    | 60       |\n",
    "| 4  | 1.65    | 45       |\n",
    "| ...| ...     | ...      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （1）请以“判断用户体型相似性”为例，说明数据规范化的必要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在“判断用户体型相似性”的场景中，数据规范化的必要性可以从以下几个方面来理解：\n",
    "\n",
    "- **尺度一致性**：身高和体重的量级和单位不同。身高通常在一米左右，而体重则是几十千克。如果直接使用这些原始数据进行相似性比较，例如通过计算欧氏距离，体重因其较大的数值将对结果产生不成比例的影响。规范化处理可以确保每个特征对相似性度量的贡献是均衡的。\n",
    "\n",
    "- **提升算法性能**：许多机器学习算法在处理数据时，如果数据特征处于相同的尺度，算法会表现得更好。比如，在使用基于距离的算法（如K-最近邻）时，未规范化的数据可能导致算法过分重视某些特征。\n",
    "\n",
    "- **加快收敛速度**：对于需要迭代求解的算法（如梯度下降），规范化的数据可以加快收敛速度，因为每个特征值对参数更新的影响大致相同。\n",
    "\n",
    "- **消除单位影响**：在比较不同单位或量级的特征时，单位和量级的差异可能会影响分析的结果。规范化可以消除这些因素的影响，使得特征之间的比较更加公平。\n",
    "\n",
    "- **增强解释性**：规范化后的数据在相同的尺度上，可以使得特征之间的比较更加直观，有助于发现数据间的真实关系。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （2）请采用 Min-Max 规范化，将表 1 用户的身高和体重数据规范化到[0,1]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性函数规范化（Min-Max Scaling）。它对原始数据进行线性变换，使结果映射到[0, 1]的范围，实现对原始数据的等比缩放。归一化公式如下：\n",
    "\n",
    "$$\n",
    "X_{norm} = \\frac{X - X_{min}}{X_{max}-X_{min}}\n",
    "$$\n",
    "\n",
    "其中$X$为原数据(raw data)，$X_norm$为规范化后数据(normalized data)\n",
    "\n",
    "本题中，身高最大值为1.7m，最小值为1.6m；本题中，身高最大值为60kg，最小值为45kg。\n",
    "\n",
    "式子就转变为\n",
    "\n",
    "$$\n",
    "height_{norm, i} =  \\frac{height_{i} - 1.6}{1.7-1.6}\n",
    "$$\n",
    "\n",
    "$$\n",
    "weight_{norm, i} =  \\frac{weight_{i} - 45}{60-45}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\forall i \\in ID\n",
    "$$\n",
    "\n",
    "分别将其带入得到:\n",
    "\n",
    "| ID | 身高_normalized | 体重_normalized |\n",
    "|----|-----------------|-------------|\n",
    "| 1  | 1.00            | 0.33        |\n",
    "| 2  | 0.00            | 0.33        |\n",
    "| 3  | 1.00            | 1.00        |\n",
    "| 4  | 0.50            | 0.00        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### （3）用户 2、3、4 中，谁和用户 1 的体型更相似？请给出结论和计算依据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据补充知识可得，我们可以根据欧式距离判断相似性。\n",
    "\n",
    "因此我们来判断各个非1的ID与ID为1的距离：\n",
    "\n",
    "$$\n",
    "D(i,1) = \\sqrt{(height_{norm,i} - 1)^2 + (weight_{norm,i} - 0.33)^2}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\forall i \\in ID\n",
    "$$\n",
    "\n",
    "$$\n",
    "i \\neq 1\n",
    "$$\n",
    "\n",
    "结果得到：\n",
    "\n",
    "| ID | 欧氏距离   |\n",
    "|----|----------|\n",
    "| 2  | 1.000000 |\n",
    "| 3  | 0.666667 |\n",
    "| 4  | 0.600925 |\n",
    "\n",
    "因此ID为4的与1最为相似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) 数据离散化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 表2. 个人信息表\n",
    "\n",
    "| 年龄(岁) | 性别 | 年收入(万元) |\n",
    "|---------|-----|------------|\n",
    "| 25      | 女  | 10         |\n",
    "| 27      | 男  | 25         |\n",
    "| 30      | 女  | 30         |\n",
    "| 45      | 男  | 60         |\n",
    "| 28      | 女  | 40         |\n",
    "| 32      | 女  | 20         |\n",
    "| 52      | 女  | 50         |\n",
    "| 35      | 男  | 30         |\n",
    "| 55      | 女  | 100        |\n",
    "| 48      | 男  | 120        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别利用等宽离散化和等深离散化将表 2 中的属性“年收入(万元)”转换为“低收入”、“中收入”和“高收入”三档。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**等宽离散化**是一种将连续型变量分成若干个等宽的区间的方法。 其原理是先确定要分成的区间数量，然后根据数据的最小值和最大值计算出每个区间的宽度，最后将数据映射到对应的区间中](https://zhuanlan.zhihu.com/p/655381873)。\n",
    "\n",
    "因此我们需要有三个区间：“低收入”、“中收入”和“高收入”。\n",
    "\n",
    "每个区间的长度为\n",
    "\n",
    "$$\n",
    "\\frac{120-10}{3} = 36.67\n",
    "$$\n",
    "\n",
    "因此，\n",
    "\n",
    " - 低收入对应 10 - 46.67 万元\n",
    " - 中收入对应 46.67 - 83.34 万元\n",
    " - 高收入对应 83.34 - 120 万元\n",
    "\n",
    " 最后得到：\n",
    "\n",
    "| 年收入(万元) | 年收入_等宽 |\n",
    "|-------------|------------|\n",
    "| 10          | 低收入       |\n",
    "| 25          | 低收入       |\n",
    "| 30          | 低收入       |\n",
    "| 60          | 中收入       |\n",
    "| 40          | 低收入       |\n",
    "| 20          | 低收入       |\n",
    "| 50          | 中收入       |\n",
    "| 30          | 低收入       |\n",
    "| 100         | 高收入       |\n",
    "| 120         | 高收入       |\n",
    "\n",
    "[**等深离散化**实际上是等频离散化(Equal-Frequency Discretization)，将特征值的累积频率分布均匀划分成若干个区间。](https://open.passingai.com/content/703.html)\n",
    "\n",
    "在等深离散化的过程中，数据被分为三个类别，具体的分类规则如下：\n",
    "\n",
    "- **低收入**：包含最低的3-4个数据点。\n",
    "- **中收入**：紧接着的3-4个数据点。\n",
    "- **高收入**：剩余的数据点。\n",
    "\n",
    "这种分类方法旨在确保每个类别中包含大致相等数量的数据点，从而反映出数据的分布特性。\n",
    "\n",
    "\n",
    "我们有 `n=10` 个数据点，并希望计算 `1/3` 和 `2/3` 的分位点位置。计算分位点位置的公式为：\n",
    "\n",
    "$$\n",
    "position = q * (n + 1)\n",
    "$$\n",
    "\n",
    "其中'q'是所求分位数(`1/3` 或 `2/3`)\n",
    "\n",
    "- 对于 `1/3` 的分位点位置：\n",
    "\n",
    "$$\n",
    "position_{\\frac{1}{3}} = \\frac{1}{3} × (10 + 1) = 3.67\n",
    "$$\n",
    "\n",
    "- 对于 `2/3` 的分位点位置：\n",
    "\n",
    "$$\n",
    "position_{\\frac{2}{3}} = \\frac{2}{3} × (10 + 1) = 7.33\n",
    "$$\n",
    "\n",
    "由于分位点位置不是整数，我们需要在相邻的数据点之间进行插值来计算分位点的实际值\n",
    "\n",
    "对于 `1/3` 的分位点值，位置大约在 3 和 4 之间，所以我们在第 3 个（30万元）和第 4 个数据点（40万元）之间插值：\n",
    "\n",
    "$$\n",
    "position_{\\frac{1}{3}} = 30 + (40-30)*(3.67-3) = 28.33\n",
    "$$\n",
    "\n",
    "对于 `2/3` 的分位点值，位置大约在 7 和 8 之间，所以我们在第 7 个（50万元）和第 8 个数据点（60万元）之间插值：\n",
    "\n",
    "$$\n",
    "position_{\\frac{2}{3}} = 50 + (60-50)*(7.33-7) = 53.33\n",
    "$$\n",
    "\n",
    "结合之前规则，\n",
    "\n",
    "| 年收入(万元) | 年收入_等深 |\n",
    "|-------------|------------|\n",
    "| 10          | 低收入       |\n",
    "| 25          | 低收入       |\n",
    "| 30          | 中收入       |\n",
    "| 60          | 高收入       |\n",
    "| 40          | 中收入       |\n",
    "| 20          | 低收入       |\n",
    "| 50          | 中收入       |\n",
    "| 30          | 低收入       |\n",
    "| 100         | 高收入       |\n",
    "| 120         | 高收入       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分类分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用 Titanic 数据集（详见 train.csv 和 test.csv），预测乘客及船员的生存情况。通过数据预处理，开展分类分析，主要进行数据集划分、模型参数选择和实验结果比较，重点实践决策树、逻辑回归和朴素贝叶斯三个算法。作业要求提交完整的分类分析报告，包括文字叙述、代码和运行结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
